{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Enfoque del dataset de noticias falsas basado en algoritmos clásicos de aprendizaje automático"
      ],
      "metadata": {
        "id": "e_Fo89pZAHZw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p1Sno_M_bhI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285c25d2-42e5-4b48-d0a3-b89df30f5c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "### IMPORTS ###\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar Dataset"
      ],
      "metadata": {
        "id": "WbjNq11JgYqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### DRIVE DATA ###\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "PATH = \"/content/drive/My Drive/TFM/Data/FakeNews_Task3_2022/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ohgLOFB5LmD",
        "outputId": "9bb1b20f-15ba-44fc-bfa9-999515dbc99a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### CONJUNTOS DE ENTRENAMIENTO, VALIDACIÓN Y TEST ###\n",
        "df_train = pd.read_csv(PATH + \"Task3_train_dev/Task3_english_training.csv\") \n",
        "df_train = df_train[['text', 'our rating']]\n",
        "df_train = df_train.rename(columns = {\"text\": \"Text\", \"our rating\": \"Label\"})\n",
        "\n",
        "df_dev = pd.read_csv(PATH + \"Task3_train_dev/Task3_english_dev.csv\") \n",
        "df_dev = df_dev[['text', 'our ratinge']]\n",
        "df_dev = df_dev.rename(columns = {\"text\": \"Text\", \"our ratinge\": \"Label\"})\n",
        "\n",
        "df_test = pd.read_csv(PATH + \"Task3_Test/English_data_test_release_with_rating.csv\") \n",
        "df_test = df_test[['text', 'our rating']]\n",
        "df_test = df_test.rename(columns = {\"text\": \"Text\", \"our rating\": \"Label\"})\n",
        "\n",
        "print('Tamaño Conjunto de Entrenamiento:', len(df_train['Label']))\n",
        "print('Tamaño Conjunto de Validación:', len(df_dev['Label']))\n",
        "print('Tamaño Conjunto de Evaluación:', len(df_test['Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Yhoi3y5MKQ",
        "outputId": "d932befb-4d65-46f3-b517-6d3b8d45a2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño Conjunto de Entrenamiento: 900\n",
            "Tamaño Conjunto de Validación: 364\n",
            "Tamaño Conjunto de Evaluación: 612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Encoding"
      ],
      "metadata": {
        "id": "eAc3QSGcgcdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### LABEL ENCODING ###\n",
        "y_train = df_train['Label'].tolist()\n",
        "y_test = df_test['Label'].tolist()\n",
        "\n",
        "LABELS = sorted(set(y_train))\n",
        "\n",
        "idx2label={}\n",
        "label2idx={}\n",
        "for index, label in enumerate(LABELS):\n",
        "    label2idx.update([(label, index)])\n",
        "    idx2label.update([(index, label)])\n",
        "\n",
        "print('Labels:', label2idx)\n",
        "le = LabelEncoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUEmCbLFVH4s",
        "outputId": "55b2dd80-333a-4044-f0ef-c5e9ac2884bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: {'False': 0, 'Other': 1, 'Partially false': 2, 'True': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limpieza y Representación de Textos"
      ],
      "metadata": {
        "id": "Y2cga-nDjtlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### LIMPIEZA DE TEXTOS ###\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "def clean_text(text):\n",
        "    # transformar a minúscula\n",
        "    text=str(text).lower()\n",
        "    # tokenizar\n",
        "    tokens=word_tokenize(text)\n",
        "    # borrar stopwords\n",
        "    tokens = [word for word in tokens if word not in stopwords_en]\n",
        "    # usar los stems\n",
        "    tokens = [PorterStemmer().stem(word) for word in tokens]\n",
        "    # eliminamos las palabras con menos de 3 caráceres\n",
        "    # ignoramos cualquier palabra que contenga un digito o un símbolo especial \n",
        "    min_length = 3\n",
        "    p = re.compile('^[a-zA-Z]+$');\n",
        "    filtered_tokens=[]\n",
        "    for token in tokens:\n",
        "        if len(token)>=min_length and p.match(token):\n",
        "            filtered_tokens.append(token)\n",
        "            \n",
        "    return filtered_tokens"
      ],
      "metadata": {
        "id": "badgpuYujv9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bolsa de Palabras"
      ],
      "metadata": {
        "id": "BB2aQGIftSjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### BOLSA DE PALABRAS ###\n",
        "X_train = df_train['Text'].tolist()\n",
        "X_test = df_test['Text'].tolist()\n",
        "\n",
        "# entrenamos un modelo de bolsa de palabras\n",
        "bow = CountVectorizer(analyzer=clean_text).fit(X_train)\n",
        "# transformamos el conjunto de entrenamiento a bolsa de palabras\n",
        "X_train_bow = bow.transform(X_train)\n",
        "# transformamos el conjunto de evaluación a bolsa de palabras\n",
        "X_test_bow=bow.transform(X_test)\n",
        "\n",
        "print(\"Tamaño del vocabulario: \", len(bow.vocabulary_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LyyJkH4tU9K",
        "outputId": "caa95e6d-aaec-4ac1-d8aa-138fcfdf8088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del vocabulario:  16672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF"
      ],
      "metadata": {
        "id": "ESXpf0ZAvLAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TF-IDF ###\n",
        "# entrenamos un modelo tf-idf \n",
        "tfidf_transformer = TfidfTransformer().fit(X_train_bow)\n",
        "# transformamos el conjunto de entrenamiento\n",
        "X_train_tfidf = tfidf_transformer.transform(X_train_bow)\n",
        "# transformamos el conjunto de entrenamiento\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_bow)"
      ],
      "metadata": {
        "id": "A6kuJq4avM_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificación Clásica\n",
        "Se crea un pipeline que ejecuta una secuencia de procesos:\n",
        "\n",
        "\n",
        "1.   La representación de los textos en bolsa de palabras (CountVectorizer), que recibe como entrada los textos, y se les aplica dentro del CountVectorizer la función clean_text para limpiarlos y reducir el ruido. \n",
        "2.   La representación en tf-idf (TfidfTransformer), recibe como entrada la salida del proceso 1, y produce los vectores tf-idf. \n",
        "3. El clasificador SVC, Logistic Regression o Random Forest Clasiffier."
      ],
      "metadata": {
        "id": "24Zza6O4wC4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### PIPELINE SVM ###\n",
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer(analyzer=clean_text)),  \n",
        "    ('tf', TfidfTransformer()),  \n",
        "    ('svm', SVC()), \n",
        "])\n",
        "\n",
        "# Parámetros para el algoritmo SVM\n",
        "grid_params_svm = [{'svm__kernel': ['linear', 'rbf'], \n",
        "                    'svm__C': [0.1, 1], # [0.1, 1, 10, 100, 1000]\n",
        "                    'svm__gamma':  [1, 0.1] # [1, 0.1, 0.01, 0.001, 0.0001]\n",
        "                    }]\n",
        "gs = GridSearchCV(pipeline, param_grid=grid_params_svm, \n",
        "                  scoring='accuracy', cv=5, verbose = 1)\n",
        "\n",
        "# entrenamos el grid\n",
        "gs.fit(X_train, y_train)\n",
        "print('Los mejores parámetros son : %s' % gs.best_params_)\n",
        "print('Mejor accuracy: %.3f' % gs.best_score_)\n",
        "print(gs.best_estimator_)\n",
        "\n",
        "best_svm = gs.best_estimator_\n",
        "predictions = best_svm.predict(X_test)\n",
        "print( classification_report(y_test, predictions, target_names=label2idx.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vlh4ZNrwFcH",
        "outputId": "1b2b79a2-792b-4e25-e063-5cd35c5a1fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Los mejores parámetros son : {'svm__C': 1, 'svm__gamma': 1, 'svm__kernel': 'linear'}\n",
            "Mejor accuracy: 0.594\n",
            "Pipeline(steps=[('bow',\n",
            "                 CountVectorizer(analyzer=<function clean_text at 0x7f731d39f0d0>)),\n",
            "                ('tf', TfidfTransformer()),\n",
            "                ('svm', SVC(C=1, gamma=1, kernel='linear'))])\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          False       0.54      0.99      0.70       315\n",
            "          Other       0.00      0.00      0.00        31\n",
            "Partially false       0.21      0.12      0.16        56\n",
            "           True       0.86      0.03      0.06       210\n",
            "\n",
            "       accuracy                           0.53       612\n",
            "      macro avg       0.40      0.29      0.23       612\n",
            "   weighted avg       0.59      0.53      0.39       612\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### PIPELINE LOGISTIC REGRESSION ###\n",
        "pipeline2 = Pipeline([\n",
        "    ('bow', CountVectorizer(analyzer=clean_text)),  \n",
        "    ('tf', TfidfTransformer()),  \n",
        "    ('lr', LogisticRegression(random_state=0)), \n",
        "])\n",
        "\n",
        "# Parámetros para el algoritmo Logistic Regression\n",
        "grid_params_lr = [{'lr__penalty': ['l1', 'l2'], \n",
        "                    'lr__C': [1.0, 0.5],\n",
        "                    'lr__solver':  ['liblinear']\n",
        "                    }]\n",
        "gs2 = GridSearchCV(pipeline2, param_grid=grid_params_lr, \n",
        "                  scoring='accuracy', cv=5, verbose = 1)\n",
        "\n",
        "# entrenamos el grid\n",
        "gs2.fit(X_train, y_train)\n",
        "print('Los mejores parámetros son : %s' % gs2.best_params_)\n",
        "print('Mejor accuracy: %.3f' % gs2.best_score_)\n",
        "print(gs2.best_estimator_)\n",
        "\n",
        "best_svm = gs2.best_estimator_\n",
        "predictions = best_svm.predict(X_test)\n",
        "print( classification_report(y_test, predictions, target_names=label2idx.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvM8_10-ajC-",
        "outputId": "77331dd0-148e-4ade-a1b1-6b8bd7b1ee8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Los mejores parámetros son : {'lr__C': 1.0, 'lr__penalty': 'l2', 'lr__solver': 'liblinear'}\n",
            "Mejor accuracy: 0.560\n",
            "Pipeline(steps=[('bow',\n",
            "                 CountVectorizer(analyzer=<function clean_text at 0x7f731d39f0d0>)),\n",
            "                ('tf', TfidfTransformer()),\n",
            "                ('lr', LogisticRegression(random_state=0, solver='liblinear'))])\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          False       0.52      0.99      0.68       315\n",
            "          Other       0.00      0.00      0.00        31\n",
            "Partially false       0.25      0.05      0.09        56\n",
            "           True       0.00      0.00      0.00       210\n",
            "\n",
            "       accuracy                           0.52       612\n",
            "      macro avg       0.19      0.26      0.19       612\n",
            "   weighted avg       0.29      0.52      0.36       612\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### PIPELINE RANDOM FOREST ###\n",
        "pipeline3 = Pipeline([\n",
        "    ('bow', CountVectorizer(analyzer=clean_text)),  \n",
        "    ('tf', TfidfTransformer()),  \n",
        "    ('rfc', RandomForestClassifier(random_state=0)), \n",
        "])\n",
        "\n",
        "# Parámetros para el algoritmo Random Forest\n",
        "grid_params_rfc = [{'rfc__criterion': ['gini', 'entropy'], \n",
        "                    'rfc__max_depth': [9, 10],\n",
        "                    'rfc__min_samples_split':  [10]\n",
        "                    }]\n",
        "gs3 = GridSearchCV(pipeline3, param_grid=grid_params_rfc, \n",
        "                  scoring='accuracy', cv=5, verbose = 1)\n",
        "\n",
        "# entrenamos el grid\n",
        "gs3.fit(X_train, y_train)\n",
        "print('Los mejores parámetros son : %s' % gs3.best_params_)\n",
        "print('Mejor accuracy: %.3f' % gs3.best_score_)\n",
        "print(gs3.best_estimator_)\n",
        "\n",
        "best_svm = gs3.best_estimator_\n",
        "predictions = best_svm.predict(X_test)\n",
        "print( classification_report(y_test, predictions, target_names=label2idx.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMuW5K410K-_",
        "outputId": "4410337b-2b70-4c58-a788-65f85afcca73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Los mejores parámetros son : {'rfc__criterion': 'gini', 'rfc__max_depth': 10, 'rfc__min_samples_split': 10}\n",
            "Mejor accuracy: 0.538\n",
            "Pipeline(steps=[('bow',\n",
            "                 CountVectorizer(analyzer=<function clean_text at 0x7f731d39f0d0>)),\n",
            "                ('tf', TfidfTransformer()),\n",
            "                ('rfc',\n",
            "                 RandomForestClassifier(max_depth=10, min_samples_split=10,\n",
            "                                        random_state=0))])\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          False       0.52      0.99      0.68       315\n",
            "          Other       0.00      0.00      0.00        31\n",
            "Partially false       0.40      0.04      0.07        56\n",
            "           True       0.00      0.00      0.00       210\n",
            "\n",
            "       accuracy                           0.51       612\n",
            "      macro avg       0.23      0.26      0.19       612\n",
            "   weighted avg       0.30      0.51      0.36       612\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}